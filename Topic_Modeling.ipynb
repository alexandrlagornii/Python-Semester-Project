{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b94c4ad",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87db8ea5",
   "metadata": {},
   "source": [
    "## Attempt 1 - All Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c007b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ab</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abbey</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>aboutany</th>\n",
       "      <th>aboutim</th>\n",
       "      <th>abscess</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>...</th>\n",
       "      <th>zacks</th>\n",
       "      <th>zane</th>\n",
       "      <th>ziggy</th>\n",
       "      <th>zip</th>\n",
       "      <th>zoo</th>\n",
       "      <th>ﬁesta</th>\n",
       "      <th>ﬁne</th>\n",
       "      <th>ﬁreworks</th>\n",
       "      <th>ﬂoor</th>\n",
       "      <th>ﬂy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Trainspotting</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The_Wrestler</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Whiplash</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coco</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rocky</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oldboy</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 4713 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ab  abandoned  abbey  ability  able  aboutany  aboutim  \\\n",
       "Trainspotting   0          0      0        0     0         0        0   \n",
       "The_Wrestler    0          0      0        2     1         0        0   \n",
       "Whiplash        0          0      0        0     3         0        0   \n",
       "Coco            0          1      0        0     0         1        1   \n",
       "Rocky           0          0      0        0     0         0        0   \n",
       "Oldboy          1          0      1        0     3         0        0   \n",
       "\n",
       "               abscess  absolute  absolutely  ...  zacks  zane  ziggy  zip  \\\n",
       "Trainspotting        1         0           2  ...      0     0      1    0   \n",
       "The_Wrestler         0         0           1  ...      0     0      0    0   \n",
       "Whiplash             0         2           1  ...      0     1      0    0   \n",
       "Coco                 0         0           0  ...      0     0      0    1   \n",
       "Rocky                0         0           6  ...      1     0      0    0   \n",
       "Oldboy               0         0           0  ...      0     0      0    0   \n",
       "\n",
       "               zoo  ﬁesta  ﬁne  ﬁreworks  ﬂoor  ﬂy  \n",
       "Trainspotting    0      0    0         0     0   0  \n",
       "The_Wrestler     0      0    0         0     0   0  \n",
       "Whiplash         0      0    0         0     0   0  \n",
       "Coco             0      1    1         1     1   1  \n",
       "Rocky            3      0    0         0     0   0  \n",
       "Oldboy           0      0    0         0     0   0  \n",
       "\n",
       "[6 rows x 4713 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read document-term matrix\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "data = pd.read_pickle('dtm_stop.pkl')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "996f8e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LDA with gensim\n",
    "from gensim import matutils, models\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "babbd44a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trainspotting</th>\n",
       "      <th>The_Wrestler</th>\n",
       "      <th>Whiplash</th>\n",
       "      <th>Coco</th>\n",
       "      <th>Rocky</th>\n",
       "      <th>Oldboy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ab</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandoned</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbey</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ability</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>able</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Trainspotting  The_Wrestler  Whiplash  Coco  Rocky  Oldboy\n",
       "ab                     0             0         0     0      0       1\n",
       "abandoned              0             0         0     1      0       0\n",
       "abbey                  0             0         0     0      0       1\n",
       "ability                0             2         0     0      0       0\n",
       "able                   0             1         3     0      0       3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transpose matrix\n",
    "tdm = data.transpose()\n",
    "tdm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc324097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term-document matrix into a gensim format; df -> sparse matrix -> gensim corpus\n",
    "sparse_counts = scipy.sparse.csr_matrix(tdm)\n",
    "corpus = matutils.Sparse2Corpus(sparse_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01b1858e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary with all term and their respective location in the term-document matrix\n",
    "cv = pickle.load(open(\"cv_stop.pkl\", \"rb\"))\n",
    "id2word = dict((v, k) for k, v in cv.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e8a70bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.014*\"yeah\" + 0.008*\"gonna\" + 0.007*\"lm\" + 0.007*\"fucking\" + 0.006*\"wanna\" + 0.006*\"look\" + 0.006*\"say\" + 0.005*\"hes\" + 0.005*\"did\" + 0.005*\"fuck\"'),\n",
       " (1,\n",
       "  '0.011*\"yeah\" + 0.011*\"fucking\" + 0.010*\"oh\" + 0.009*\"ram\" + 0.008*\"want\" + 0.006*\"fuck\" + 0.006*\"going\" + 0.005*\"family\" + 0.005*\"miguel\" + 0.005*\"la\"'),\n",
       " (2,\n",
       "  '0.011*\"daesu\" + 0.008*\"oh\" + 0.006*\"ill\" + 0.006*\"years\" + 0.006*\"did\" + 0.006*\"really\" + 0.005*\"want\" + 0.004*\"let\" + 0.004*\"lee\" + 0.004*\"mido\"')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify number of topics and number of passes\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=3, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ade501d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.024*\"yeah\" + 0.016*\"ram\" + 0.013*\"oh\" + 0.011*\"fuck\" + 0.010*\"fucking\" + 0.009*\"gonna\" + 0.008*\"want\" + 0.008*\"really\" + 0.007*\"uh\" + 0.006*\"ill\"'),\n",
       " (1,\n",
       "  '0.013*\"lm\" + 0.011*\"yeah\" + 0.009*\"rocky\" + 0.009*\"aint\" + 0.008*\"fight\" + 0.008*\"wanna\" + 0.007*\"look\" + 0.007*\"hes\" + 0.007*\"yo\" + 0.006*\"say\"'),\n",
       " (2,\n",
       "  '0.001*\"yeah\" + 0.000*\"oh\" + 0.000*\"want\" + 0.000*\"fucking\" + 0.000*\"did\" + 0.000*\"look\" + 0.000*\"say\" + 0.000*\"gonna\" + 0.000*\"lm\" + 0.000*\"hes\"'),\n",
       " (3,\n",
       "  '0.001*\"yeah\" + 0.000*\"fucking\" + 0.000*\"want\" + 0.000*\"oh\" + 0.000*\"going\" + 0.000*\"look\" + 0.000*\"really\" + 0.000*\"fuck\" + 0.000*\"make\" + 0.000*\"need\"'),\n",
       " (4,\n",
       "  '0.011*\"fucking\" + 0.007*\"going\" + 0.007*\"oh\" + 0.007*\"want\" + 0.006*\"family\" + 0.006*\"did\" + 0.005*\"miguel\" + 0.005*\"la\" + 0.005*\"really\" + 0.004*\"ill\"')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify number of topics and number of passes\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=5, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6833f9",
   "metadata": {},
   "source": [
    "## Attempt 2 - Noun Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ea60480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's creat a function to pull out nouns from a string of text\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "def nouns(text):\n",
    "    '''Giben a string of text, tokenize the text and pull out only the nouns.'''\n",
    "    is_noun = lambda pos: pos[:2] == 'NN'\n",
    "    tokenized = word_tokenize(text)\n",
    "    all_nouns = [word for (word, pos) in pos_tag(tokenized) if is_noun(pos)]\n",
    "    return ' '.join(all_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b0b9612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the cleaned data\n",
    "data_clean = pd.read_pickle('data_clean.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d32af32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Trainspotting</th>\n",
       "      <td>career family fucking television choose machin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The_Wrestler</th>\n",
       "      <td>peoples ram robinson ram haymakers pile driver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Whiplash</th>\n",
       "      <td>stay name sir year year players ask i answer m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coco</th>\n",
       "      <td>something happenedbefore i time family papa mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rocky</th>\n",
       "      <td>youre sucker action youre fightin bum advice w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oldboy</th>\n",
       "      <td>i i story hell way fuck name someone elses hol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      transcript\n",
       "Trainspotting  career family fucking television choose machin...\n",
       "The_Wrestler   peoples ram robinson ram haymakers pile driver...\n",
       "Whiplash       stay name sir year year players ask i answer m...\n",
       "Coco           something happenedbefore i time family papa mu...\n",
       "Rocky          youre sucker action youre fightin bum advice w...\n",
       "Oldboy         i i story hell way fuck name someone elses hol..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the nouns function to the transcripts to filter only on nouns\n",
    "data_nouns = pd.DataFrame(data_clean.transcript.apply(nouns))\n",
    "data_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3184699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abbey</th>\n",
       "      <th>ability</th>\n",
       "      <th>aboutany</th>\n",
       "      <th>abscess</th>\n",
       "      <th>academy</th>\n",
       "      <th>accident</th>\n",
       "      <th>accidenthow</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>actin</th>\n",
       "      <th>...</th>\n",
       "      <th>yourshow</th>\n",
       "      <th>yousay</th>\n",
       "      <th>youstay</th>\n",
       "      <th>youthe</th>\n",
       "      <th>youve</th>\n",
       "      <th>zoo</th>\n",
       "      <th>ﬁesta</th>\n",
       "      <th>ﬁne</th>\n",
       "      <th>ﬁreworks</th>\n",
       "      <th>ﬂoor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Trainspotting</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The_Wrestler</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Whiplash</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coco</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rocky</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oldboy</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 2768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               abbey  ability  aboutany  abscess  academy  accident  \\\n",
       "Trainspotting      0        0         0        1        1         1   \n",
       "The_Wrestler       0        2         0        0        0         0   \n",
       "Whiplash           0        0         0        0        0         1   \n",
       "Coco               0        0         1        0        0         0   \n",
       "Rocky              0        0         0        0        0         0   \n",
       "Oldboy             1        0         0        0        0         0   \n",
       "\n",
       "               accidenthow  account  act  actin  ...  yourshow  yousay  \\\n",
       "Trainspotting            0        1    1      0  ...         0       0   \n",
       "The_Wrestler             0        0    0      0  ...         0       0   \n",
       "Whiplash                 0        0    0      0  ...         0       0   \n",
       "Coco                     1        0    1      0  ...         1       1   \n",
       "Rocky                    0        0    0      1  ...         0       0   \n",
       "Oldboy                   0        0    0      0  ...         0       0   \n",
       "\n",
       "               youstay  youthe  youve  zoo  ﬁesta  ﬁne  ﬁreworks  ﬂoor  \n",
       "Trainspotting        0       0     10    0      0    0         0     0  \n",
       "The_Wrestler         0       0      2    0      0    0         0     0  \n",
       "Whiplash             0       0      0    0      0    0         0     0  \n",
       "Coco                 1       3      0    0      1    1         1     1  \n",
       "Rocky                0       0      0    3      0    0         0     0  \n",
       "Oldboy               0       0      1    0      0    0         0     0  \n",
       "\n",
       "[6 rows x 2768 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new document_term matrix using only nouns\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Re-add the additional stop words\n",
    "add_stop_words = ['ive', 'like', 'im', 'know', 'just', 'dont', 'thats', 'right', 'people',\n",
    "                 'youre', 'got', 'gonna', 'time', 'think', 'want', 'yeah', 'say', 'hi', 'hello', 'ha'\n",
    "                 , 'ok', 'uhoh', 'okay', 'lets', 'hey', 'ram', 'jam', 'ramjam', 'yo', 'gon', 'oh', 'mr']\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)\n",
    "\n",
    "# Recreate a document-term matrix with only nouns\n",
    "cvn = CountVectorizer(stop_words=stop_words)\n",
    "data_cvn = cvn.fit_transform(data_nouns.transcript)\n",
    "data_dtmn = pd.DataFrame(data_cvn.toarray(), columns=cvn.get_feature_names_out())\n",
    "data_dtmn.index = data_nouns.index\n",
    "data_dtmn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3700b94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create gensim corpus\n",
    "corpusn = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmn.transpose()))\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2wordn = dict((v, k) for k, v in cvn.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81f5a5f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.009*\"fucking\" + 0.009*\"man\" + 0.009*\"years\" + 0.009*\"daesu\" + 0.008*\"way\" + 0.006*\"life\" + 0.006*\"cunt\" + 0.005*\"day\" + 0.005*\"thing\" + 0.005*\"hit\"'),\n",
       " (1,\n",
       "  '0.001*\"man\" + 0.001*\"family\" + 0.001*\"fuck\" + 0.001*\"hes\" + 0.001*\"home\" + 0.001*\"music\" + 0.001*\"way\" + 0.001*\"years\" + 0.001*\"look\" + 0.000*\"world\"'),\n",
       " (2,\n",
       "  '0.022*\"man\" + 0.010*\"fuck\" + 0.008*\"look\" + 0.007*\"hes\" + 0.006*\"lot\" + 0.005*\"guys\" + 0.005*\"thanks\" + 0.005*\"whats\" + 0.005*\"night\" + 0.005*\"things\"'),\n",
       " (3,\n",
       "  '0.024*\"family\" + 0.014*\"miguel\" + 0.013*\"music\" + 0.009*\"home\" + 0.009*\"héctor\" + 0.008*\"mama\" + 0.008*\"papa\" + 0.008*\"guitar\" + 0.007*\"dante\" + 0.007*\"photo\"')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try different amount of topics\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=4, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12932cf0",
   "metadata": {},
   "source": [
    "## Attempt 3 - Nouns and Adjectives only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "267fcc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nouns_adj(text):\n",
    "    '''Giben a string of text, tokenize the text and pull out only the nouns and adjectives.'''\n",
    "    is_noun_adj = lambda pos: pos[:2] == 'NN' or pos[:2] == 'JJ'\n",
    "    tokenized = word_tokenize(text)\n",
    "    all_nouns = [word for (word, pos) in pos_tag(tokenized) if is_noun_adj(pos)]\n",
    "    return ' '.join(all_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2ed735f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Trainspotting</th>\n",
       "      <td>career family fucking big television choose ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The_Wrestler</th>\n",
       "      <td>true american peoples ram robinson ram haymake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Whiplash</th>\n",
       "      <td>stay name neiman sir year first year im player...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coco</th>\n",
       "      <td>something happenedbefore i long time family pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rocky</th>\n",
       "      <td>youre sucker action youre fightin bum advice w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oldboy</th>\n",
       "      <td>anniversary i i story hell way fuck name oh da...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      transcript\n",
       "Trainspotting  career family fucking big television choose ma...\n",
       "The_Wrestler   true american peoples ram robinson ram haymake...\n",
       "Whiplash       stay name neiman sir year first year im player...\n",
       "Coco           something happenedbefore i long time family pa...\n",
       "Rocky          youre sucker action youre fightin bum advice w...\n",
       "Oldboy         anniversary i i story hell way fuck name oh da..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the nouns_adjective function to the transcripts to filter only on nouns and adjectives\n",
    "data_nouns_adj = pd.DataFrame(data_clean.transcript.apply(nouns_adj))\n",
    "data_nouns_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc9ec7c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ab</th>\n",
       "      <th>abbey</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>aboutany</th>\n",
       "      <th>aboutim</th>\n",
       "      <th>abscess</th>\n",
       "      <th>absolute</th>\n",
       "      <th>abuelita</th>\n",
       "      <th>academy</th>\n",
       "      <th>...</th>\n",
       "      <th>youstop</th>\n",
       "      <th>youthe</th>\n",
       "      <th>youve</th>\n",
       "      <th>yoyo</th>\n",
       "      <th>ziggy</th>\n",
       "      <th>zoo</th>\n",
       "      <th>ﬁesta</th>\n",
       "      <th>ﬁne</th>\n",
       "      <th>ﬁreworks</th>\n",
       "      <th>ﬂoor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Trainspotting</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The_Wrestler</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Whiplash</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coco</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rocky</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oldboy</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 3492 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ab  abbey  ability  able  aboutany  aboutim  abscess  absolute  \\\n",
       "Trainspotting   0      0        0     0         0        0        1         0   \n",
       "The_Wrestler    0      0        2     1         0        0        0         0   \n",
       "Whiplash        0      0        0     3         0        0        0         2   \n",
       "Coco            0      0        0     0         1        1        0         0   \n",
       "Rocky           0      0        0     0         0        0        0         0   \n",
       "Oldboy          1      1        0     3         0        0        0         0   \n",
       "\n",
       "               abuelita  academy  ...  youstop  youthe  youve  yoyo  ziggy  \\\n",
       "Trainspotting         0        1  ...        0       0     11     0      1   \n",
       "The_Wrestler          0        0  ...        0       0      7     0      0   \n",
       "Whiplash              0        0  ...        0       0      0     0      0   \n",
       "Coco                  5        0  ...        1       3      0     0      0   \n",
       "Rocky                 0        0  ...        0       0      0     2      0   \n",
       "Oldboy                0        0  ...        0       0      1     0      0   \n",
       "\n",
       "               zoo  ﬁesta  ﬁne  ﬁreworks  ﬂoor  \n",
       "Trainspotting    0      0    0         0     0  \n",
       "The_Wrestler     0      0    0         0     0  \n",
       "Whiplash         0      0    0         0     0  \n",
       "Coco             0      1    1         1     1  \n",
       "Rocky            3      0    0         0     0  \n",
       "Oldboy           0      0    0         0     0  \n",
       "\n",
       "[6 rows x 3492 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recreate a document-term matrix with only nouns and adjectives also remove common words with max_df\n",
    "cvna = CountVectorizer(stop_words=stop_words)\n",
    "data_cvna = cvna.fit_transform(data_nouns_adj.transcript)\n",
    "data_dtmna = pd.DataFrame(data_cvna.toarray(), columns=cvna.get_feature_names_out())\n",
    "data_dtmna.index = data_nouns_adj.index\n",
    "data_dtmna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08ce78ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create gensim corpus\n",
    "corpusna = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmna.transpose()))\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2wordna = dict((v, k) for k, v in cvna.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb613610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.019*\"man\" + 0.016*\"good\" + 0.010*\"uh\" + 0.010*\"fuck\" + 0.007*\"little\" + 0.007*\"randy\" + 0.006*\"leg\" + 0.006*\"ill\" + 0.005*\"big\" + 0.005*\"ah\"'),\n",
       " (1,\n",
       "  '0.011*\"family\" + 0.010*\"good\" + 0.008*\"miguel\" + 0.007*\"music\" + 0.006*\"lm\" + 0.006*\"hes\" + 0.005*\"night\" + 0.005*\"papa\" + 0.005*\"mama\" + 0.005*\"home\"'),\n",
       " (2,\n",
       "  '0.011*\"fucking\" + 0.010*\"good\" + 0.008*\"fuck\" + 0.008*\"man\" + 0.006*\"daesu\" + 0.006*\"sorry\" + 0.006*\"years\" + 0.004*\"way\" + 0.004*\"ill\" + 0.004*\"tommy\"')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try different amount of topics\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=3, id2word=id2wordna, passes=200)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d05d29a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 'Trainspotting'),\n",
       " (0, 'The_Wrestler'),\n",
       " (2, 'Whiplash'),\n",
       " (1, 'Coco'),\n",
       " (1, 'Rocky'),\n",
       " (2, 'Oldboy')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which topics each episode contains\n",
    "corpus_transformed = ldana[corpusna]\n",
    "list(zip([a for [(a, b)] in corpus_transformed], data_dtmna.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7908b913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
